{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2df30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL:\n",
      "SELECT p.productname, COUNT(o.orderid) AS delayed_delivery_count\n",
      "FROM robot_vacuum.orders o\n",
      "JOIN robot_vacuum.product p ON o.productid = p.productid\n",
      "WHERE LOWER(o.deliverystatus) LIKE '%delayed%' AND o.deliveryzipcode LIKE '606%'\n",
      "GROUP BY p.productname\n",
      "ORDER BY delayed_delivery_count DESC\n",
      "\n",
      "Error: None\n",
      "\n",
      "Result:\n",
      "         productname  delayed_delivery_count\n",
      "0      ILIFE V3s Pro                      69\n",
      "1   iRobot Roomba j7                      68\n",
      "2  Dyson 360 Vis Nav                      33\n",
      "3     Shark AV2501AE                      32\n",
      "4  iRobot Roomba i5+                      31\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from typing import TypedDict, Optional\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.base import Engine\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 1. STATE DEFINITION\n",
    "# =====================================================\n",
    "\n",
    "class AgentState(TypedDict, total=False):\n",
    "    question: str\n",
    "    sql: Optional[str]\n",
    "    df: Optional[pd.DataFrame]\n",
    "    error: Optional[str]\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. POSTGRES + SQLALCHEMY ENGINE\n",
    "# =====================================================\n",
    "\n",
    "PG_HOST = os.getenv(\"PG_HOST\", \"localhost\")\n",
    "PG_PORT = int(os.getenv(\"PG_PORT\", \"5433\"))\n",
    "PG_USER = os.getenv(\"PG_USER\", \"postgres\")\n",
    "PG_PASSWORD = os.getenv(\"PG_PASSWORD\", \"admin\")\n",
    "PG_DB = os.getenv(\"PG_DB\", \"robot_vacuum\")\n",
    "\n",
    "DATABASE_URL = (\n",
    "    f\"postgresql+psycopg2://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "    \"?options=-csearch_path=robot_vacuum\"\n",
    ")\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. DYNAMIC SCHEMA LOADING\n",
    "# =====================================================\n",
    "\n",
    "def generate_schema_json() -> str:\n",
    "    \"\"\"\n",
    "    Reads schema metadata dynamically from PostgreSQL\n",
    "    and returns a JSON structure for LLM prompt.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        table_name,\n",
    "        column_name,\n",
    "        data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'robot_vacuum'\n",
    "    ORDER BY table_name, ordinal_position;\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "\n",
    "    schema = {}\n",
    "    for table in df[\"table_name\"].unique():\n",
    "        cols = df[df[\"table_name\"] == table]\n",
    "        schema[table] = {\n",
    "            row[\"column_name\"]: row[\"data_type\"]\n",
    "            for _, row in cols.iterrows()\n",
    "        }\n",
    "\n",
    "    return json.dumps(schema, indent=2)\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 4. LLM SETUP + UPDATED PROMPT\n",
    "# =====================================================\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "sql_prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\",\n",
    "\"\"\"\n",
    "You are a PostgreSQL SQL expert. Always follow these rules:\n",
    "\n",
    "1. Fully qualify ONLY table names:\n",
    "      robot_vacuum.orders\n",
    "      robot_vacuum.product\n",
    "      robot_vacuum.customer\n",
    "   â†’ NEVER write robot_vacuum.table.column  \n",
    "     (this is invalid).\n",
    "\n",
    "   Correct:\n",
    "      robot_vacuum.orders\n",
    "      orders.productid\n",
    "\n",
    "   Incorrect:\n",
    "      robot_vacuum.orders.productid\n",
    "\n",
    "2. Use table aliases when helpful.\n",
    "\n",
    "3. ONLY generate a single SELECT query.\n",
    "   - No comments\n",
    "   - No non-SELECT SQL\n",
    "\n",
    "4. Use only columns present in the schema.\n",
    "\n",
    "5. For delayed deliveries:\n",
    "      LOWER(orders.deliverystatus) LIKE '%delayed%'\n",
    "\n",
    "6. For Chicago ZIP codes:\n",
    "      orders.deliveryzipcode LIKE '606%'\n",
    "\n",
    "---------------------------------------------------------\n",
    "LIVE DATABASE SCHEMA:\n",
    "{schema_json}\n",
    "---------------------------------------------------------\n",
    "\n",
    "Return ONLY the SQL query.\n",
    "\"\"\")\n",
    ",\n",
    "(\"human\", \"Question: {question}\\nSQL:\")\n",
    "])\n",
    "\n",
    "sql_chain = sql_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def clean_sql_output(raw: str) -> str:\n",
    "    \"\"\"Cleans markdown fences and validates SELECT-only.\"\"\"\n",
    "    sql = raw.strip()\n",
    "\n",
    "    if sql.lower().startswith(\"```sql\"):\n",
    "        sql = sql[6:]\n",
    "    if sql.startswith(\"```\"):\n",
    "        sql = sql[3:]\n",
    "    if sql.endswith(\"```\"):\n",
    "        sql = sql[:-3]\n",
    "\n",
    "    sql = sql.strip().rstrip(\";\")\n",
    "\n",
    "    if not sql.lower().lstrip().startswith(\"select\"):\n",
    "        raise ValueError(f\"LLM returned non-SELECT SQL:\\n{sql}\")\n",
    "\n",
    "    return sql\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 5. LANGGRAPH NODES\n",
    "# =====================================================\n",
    "\n",
    "def node_generate_sql(state: AgentState) -> AgentState:\n",
    "    question = state.get(\"question\")\n",
    "    if not question:\n",
    "        return {**state, \"error\": \"No question provided.\"}\n",
    "\n",
    "    try:\n",
    "        schema_json = generate_schema_json()\n",
    "\n",
    "        raw_sql = sql_chain.invoke({\n",
    "            \"question\": question,\n",
    "            \"schema_json\": schema_json\n",
    "        })\n",
    "\n",
    "        sql = clean_sql_output(raw_sql)\n",
    "\n",
    "        return {**state, \"sql\": sql, \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {**state, \"error\": f\"SQL generation failed: {e}\"}\n",
    "\n",
    "\n",
    "def node_run_sql(state: AgentState) -> AgentState:\n",
    "    sql = state.get(\"sql\")\n",
    "\n",
    "    if not sql:\n",
    "        return state\n",
    "\n",
    "    if state.get(\"error\"):\n",
    "        return state\n",
    "\n",
    "    try:\n",
    "        df = pd.read_sql_query(text(sql), engine)\n",
    "        return {**state, \"df\": df, \"error\": None}\n",
    "    except Exception as e:\n",
    "        return {**state, \"error\": f\"SQL execution failed: {e}\"}\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 6. BUILD LANGGRAPH\n",
    "# =====================================================\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"generate_sql\", node_generate_sql)\n",
    "builder.add_node(\"run_sql\", node_run_sql)\n",
    "\n",
    "builder.set_entry_point(\"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"run_sql\")\n",
    "builder.add_edge(\"run_sql\", END)\n",
    "\n",
    "agent_app = builder.compile()\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 7. LOCAL TEST\n",
    "# =====================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_question = \"Which products have the highest number of delayed deliveries in Chicago?\"\n",
    "\n",
    "    state = {\n",
    "        \"question\": sample_question\n",
    "    }\n",
    "\n",
    "    result = agent_app.invoke(state)\n",
    "\n",
    "    print(\"Generated SQL:\")\n",
    "    print(result.get(\"sql\"))\n",
    "\n",
    "    print(\"\\nError:\", result.get(\"error\"))\n",
    "\n",
    "    df = result.get(\"df\")\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        print(\"\\nResult:\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(\"No DataFrame returned.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e5559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
